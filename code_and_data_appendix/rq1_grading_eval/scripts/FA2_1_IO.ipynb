{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hMounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai==0.27.0 --quiet\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "import openai\n",
    "openai.api_key = userdata.get(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "model_ids = [model.id for model in openai.Model.list().data]\n",
    "assert MODEL in model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change FA and ABLATION in between ablations for same FA\n",
    "FA = \"2\"\n",
    "ABLATION = f\"_1_IO\"\n",
    "\n",
    "FA_COLS = [\n",
    "    \"less_than_condition\",\n",
    "    \"less_than_set_absorption\",\n",
    "    \"less_than_set_runoff\",\n",
    "    \"equal_to_condition\",\n",
    "    \"equal_to_set_absorption\",\n",
    "    \"equal_to_set_runoff\",\n",
    "    \"greater_than_condition\",\n",
    "    \"greater_than_set_absorption\",\n",
    "    \"greater_than_set_runoff\",\n",
    "]\n",
    "\n",
    "FA_COLS_DICT = {k: None for k in FA_COLS}\n",
    "\n",
    "DATA_PATH = \"\"\n",
    "PROMPT_PATH = \"\"\n",
    "RESULTS_PATH = \"\"\n",
    "\n",
    "ROLE_CONTENT_DELIM = \"!~*~!\"\n",
    "SEED = 312\n",
    "N_BOOTSTRAP = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROMPT_PATH, 'r', encoding='utf-8') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(messages):\n",
    "  start_time = time.time()\n",
    "  response = openai.ChatCompletion.create(\n",
    "      model=MODEL,\n",
    "      messages=messages,\n",
    "      temperature=0,\n",
    "      response_format={\"type\": \"json_object\"},\n",
    "      seed=SEED)\n",
    "  total_time = time.time()-start_time\n",
    "  total_tokens = response[\"usage\"][\"total_tokens\"]\n",
    "  generation = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "  return generation, total_time, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n    \"working\": true,\\n    \"explanation\": \"The API is functioning correctly as there are no reported issues or errors in the current system status.\"\\n}', 0.8526895046234131, 65)\n"
     ]
    }
   ],
   "source": [
    "response = get_openai_response([{\"role\":\"system\",\"content\":\"Confirm that the api is working. Respond using the following JSON schema: {'working':bool, 'explanation':str}\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED FA2 STUDENT 0.\n",
      "FINISHED FA2 STUDENT 1.\n",
      "FINISHED FA2 STUDENT 2.\n",
      "FINISHED FA2 STUDENT 3.\n",
      "FINISHED FA2 STUDENT 4.\n",
      "FINISHED FA2 STUDENT 5.\n",
      "FINISHED FA2 STUDENT 6.\n",
      "FINISHED FA2 STUDENT 7.\n",
      "FINISHED FA2 STUDENT 8.\n",
      "FINISHED FA2 STUDENT 9.\n",
      "FINISHED FA2 STUDENT 10.\n",
      "FINISHED FA2 STUDENT 11.\n",
      "FINISHED FA2 STUDENT 12.\n",
      "FINISHED FA2 STUDENT 13.\n",
      "FINISHED FA2 STUDENT 14.\n",
      "FINISHED FA2 STUDENT 15.\n",
      "FINISHED FA2 STUDENT 16.\n",
      "FINISHED FA2 STUDENT 17.\n",
      "FINISHED FA2 STUDENT 18.\n",
      "FINISHED FA2 STUDENT 19.\n",
      "FINISHED FA2 STUDENT 20.\n",
      "FINISHED FA2 STUDENT 21.\n",
      "FINISHED FA2 STUDENT 22.\n",
      "FINISHED FA2 STUDENT 23.\n",
      "FINISHED FA2 STUDENT 24.\n",
      "FINISHED FA2 STUDENT 25.\n",
      "FINISHED FA2 STUDENT 26.\n",
      "FINISHED FA2 STUDENT 27.\n",
      "FINISHED FA2 STUDENT 28.\n",
      "FINISHED FA2 STUDENT 29.\n",
      "FINISHED FA2 STUDENT 30.\n",
      "FINISHED FA2 STUDENT 31.\n",
      "FINISHED FA2 STUDENT 32.\n",
      "FINISHED FA2 STUDENT 33.\n",
      "FINISHED FA2 STUDENT 34.\n",
      "FINISHED FA2 STUDENT 35.\n",
      "FINISHED FA2 STUDENT 36.\n",
      "FINISHED FA2 STUDENT 37.\n",
      "FINISHED FA2 STUDENT 38.\n",
      "FINISHED FA2 STUDENT 39.\n",
      "FINISHED FA2 STUDENT 40.\n",
      "FINISHED FA2 STUDENT 41.\n",
      "FINISHED FA2 STUDENT 42.\n",
      "FINISHED FA2 STUDENT 43.\n",
      "FINISHED FA2 STUDENT 44.\n",
      "FINISHED FA2 STUDENT 45.\n",
      "FINISHED FA2 STUDENT 46.\n",
      "FINISHED FA2 STUDENT 47.\n",
      "FINISHED FA2 STUDENT 48.\n",
      "FINISHED FA2 STUDENT 49.\n"
     ]
    }
   ],
   "source": [
    "results = [FA_COLS+[\"total_score\",\"total_time_s\",\"total_tokens\"]]\n",
    "\n",
    "prompt_split = prompt.split(ROLE_CONTENT_DELIM)\n",
    "system_role, system_content = prompt_split[0], prompt_split[1]\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "  messages = [\n",
    "        {\"role\":system_role,\"content\":system_content},\n",
    "        {\"role\":\"user\",\"content\":row['response']}\n",
    "  ]\n",
    "\n",
    "  generation, total_time, total_tokens = get_openai_response(messages)\n",
    "  generation_data = json.loads(generation)\n",
    "\n",
    "  for k in FA_COLS:\n",
    "    FA_COLS_DICT[k] = int(generation_data[k])\n",
    "\n",
    "  total_score = sum(FA_COLS_DICT.values())\n",
    "\n",
    "  results.append([FA_COLS_DICT[col] for col in FA_COLS]+[total_score,total_time,total_tokens])\n",
    "\n",
    "  print(f\"FINISHED FA{FA} STUDENT {idx}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results[1:],columns=results[0])\n",
    "df = pd.concat([df,df_results],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf=RESULTS_PATH,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro‑F1: 0.6200\n",
      "QWK:      0.9128\n"
     ]
    }
   ],
   "source": [
    "y_true = df[\"score\"].astype(int)\n",
    "y_pred = df[\"total_score\"].astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "print(f\"Micro‑F1: {f1:.4f}\")\n",
    "print(f\"QWK:      {qwk:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro‑F1: 62.00 ± 13.00\n",
      "QWK:      91.28 ± 7.37\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "f1_samples   = []\n",
    "kappa_samples = []\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "for _ in range(N_BOOTSTRAP):\n",
    "    idx = rng.integers(0, n, n)\n",
    "    y_t = y_true.iloc[idx].values\n",
    "    y_p = y_pred.iloc[idx].values\n",
    "\n",
    "    f1_samples.append(\n",
    "        f1_score(y_t, y_p, average=\"micro\")\n",
    "    )\n",
    "    kappa_samples.append(\n",
    "        cohen_kappa_score(y_t, y_p, weights=\"quadratic\")\n",
    "    )\n",
    "\n",
    "ci_f1   = np.percentile(f1_samples, [2.5, 97.5])\n",
    "ci_kappa = np.percentile(kappa_samples, [2.5, 97.5])\n",
    "\n",
    "moe_f1   = (ci_f1[1]   - ci_f1[0])   / 2\n",
    "moe_kappa = (ci_kappa[1] - ci_kappa[0]) / 2\n",
    "\n",
    "print(f\"Micro‑F1: {f1*100:.2f} ± {moe_f1*100:.2f}\")\n",
    "print(f\"QWK:      {qwk*100:.2f} ± {moe_kappa*100:.2f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
