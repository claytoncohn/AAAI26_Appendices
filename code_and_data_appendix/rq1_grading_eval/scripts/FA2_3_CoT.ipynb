{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=userdata.get(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "model_ids = [m.id for m in client.models.list().data]\n",
    "assert MODEL in model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change FA and ABLATION in between ablations for same FA\n",
    "FA = \"2\"\n",
    "ABLATION = f\"_3_CoT\"\n",
    "\n",
    "FA_COLS = [\n",
    "    \"less_than_condition\",\n",
    "    \"less_than_set_absorption\",\n",
    "    \"less_than_set_runoff\",\n",
    "    \"equal_to_condition\",\n",
    "    \"equal_to_set_absorption\",\n",
    "    \"equal_to_set_runoff\",\n",
    "    \"greater_than_condition\",\n",
    "    \"greater_than_set_absorption\",\n",
    "    \"greater_than_set_runoff\",\n",
    "]\n",
    "\n",
    "FA_COLS_DICT = {k: None for k in FA_COLS}\n",
    "\n",
    "DATA_PATH = \"\"\n",
    "PROMPT_PATH = \"\"\n",
    "RESULTS_PATH = \"\"\n",
    "\n",
    "ROLE_CONTENT_DELIM = \"!~*~!\"\n",
    "\n",
    "# Add this if going from I/O to ICL\n",
    "LINE_DELIM = \"\\n!@#@!\\n\"\n",
    "\n",
    "SEED = 312\n",
    "N_BOOTSTRAP = 5000\n",
    "\n",
    "# Number of few-shot instances * 2 + 1\n",
    "N_PROMPT_MESSAGES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'system!~*~!You are a teacher whose job it is to score middle school student short answer formative assessment question responses in the Earth Science domain.\\n\\nPrior to this particular formative assessment, students are taught different \"rules\" about the relationships between rainfall, absorption, absorption limit, and water runoff. Students are then tasked with the following: \\n\\nWrite down each rule (recall the IF and THEN multiple choice from today for each category of rainfall).\\n\\nIn total, there are three rules the students are required to identify:\\n1. If rainfall is less than absorption limit, set absorption to rainfall and set runoff to 0.\\n2. If rainfall is equal to absorption limit, set absorption to either rainfall or absorption limit, and set runoff to 0.\\n3. If rainfall is greater than absorption limit, set absorption to absorption limit and set runoff to either rainfall - absorption limit or rainfall - absorption.\\n\\nYou are to score student responses based on the following rubric to see how accurately each student can recall the three rules:\\n\\nLess Than Condition [0 or 1]: 1 point if the student correctly includes the conditional statement \"if rainfall is less than absorption limit\" in his or her rules. 0 points if the student does not mention the \"less than\" condition.\\nLess Than Set Absorption [0 or 1]: 1 point if the student correctly sets absorption equal to rainfall in the \"less than\" condition. 0 points if the student does not correctly set absorption in the \"less than\" condition.\\nLess Than Set Runoff [0 or 1]: 1 point if the student correctly sets runoff equal to 0 in the \"less than\" condition. 0 points if the student does not correctly set runoff in the \"less than\" condition.\\nEqual To Condition [0 or 1]: 1 point if the student correctly includes the conditional statement \"if rainfall is equal to absorption limit\" in his or her rules. 0 points if the student does not mention the \"equal to\" condition.\\nEqual To Set Absorption [0 or 1]: 1 point if the student correctly sets absorption equal to either rainfall or absorption limit in the \"equal to\" condition. 0 points if the student does not correctly set absorption in the \"equal to\" condition.\\nEqual To Set Runoff [0 or 1]: 1 point if the student correctly sets runoff equal to 0 in the \"equal to\" condition. 0 points if the student does not correctly set runoff in the \"equal to\" condition.\\nGreater Than Condition [0 or 1]: 1 point if the student correctly includes the conditional statement \"if rainfall is greater than absorption limit\" in his or her rules. 0 points if the student does not mention the \"greater than\" condition.\\nGreater Than Set Absorption [0 or 1]: 1 point if the student correctly sets absorption equal to absorption limit in the \"greater than\" condition. 0 points if the student does not correctly set absorption in the \"greater than\" condition.\\nGreater Than Set Runoff [0 or 1]: 1 point if the student correctly sets runoff equal to either rainfall - absorption limit or rainfall - absorption in the \"greater than\" condition. 0 points if the student does not correctly set runoff in the \"greater than\" condition.\\n\\nBased on all of this information, score the following student\\'s formative assessment response pursuant to the rubric. Please provide your scores as a JSON document that conforms to the following schema, providing an explanation before rendering a score:\\n\\n{\\n  \"less_than_condition\" :\\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"less_than_set_absorption\" :\\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"less_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"equal_to_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"equal_to_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"equal_to_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"greater_than_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"greater_than_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t},\\n  \"greater_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": string,\\n\\t\\t\"score\": int\\n\\t}\\n}\\n!@#@!\\nuser!~*~!If rainfall is less than absorption limit, set absorption to rainfall, and set runoff to 0.\\n\\nIf rainfall is equal to absorption limit, set absorption to absorption limit (or rainfall), and set runoff to 0.\\n\\nIf rainfall is greater than absorption limit, set absorption to absorption limit, and set runoff to rainfall minus absorption limit (or rainfall minus absorption).\\n!@#@!\\nassistant!~*~!{\\n  \"less_than_condition\" :\\n\\t{\\n\\t\\t\"explanation\": \"The student said, \\'If rainfall is less than absorption limit\\'. The rubric states that the student should be awarded \\'1 point if the student correctly includes the conditional statement \\'if rainfall is less than absorption limit\\' in his or her rules.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"less_than_set_absorption\" :\\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set absorption to rainfall\\' inside the less than condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets absorption equal to rainfall in the \\'less than\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"less_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set runoff to 0\\' inside the less than condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets runoff equal to 0 in the \\'less than\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"equal_to_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student said, \\'If rainfall is equal to absorption limit\\'. The rubric states that the student should be awarded \\'1 point if the student correctly includes the conditional statement \\'if rainfall is equal to absorption limit\\' in his or her rules.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"equal_to_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set absorption to absorption limit (or rainfall)\\' inside the equal to condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets absorption equal to either rainfall or absorption limit in the \\'equal to\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"equal_to_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set runoff to 0\\' inside the equal to condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets runoff equal to 0 in the \\'equal to\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"greater_than_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student said, \\'If rainfall is greater than absorption limit\\'. The rubric states that the student should be awarded \\'1 point if the student correctly includes the conditional statement \\'if rainfall is greater than absorption limit\\' in his or her rules.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"greater_than_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set absorption to absorption limit\\' inside the greater than condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets absorption equal to absorption limit in the \\'greater than\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t},\\n  \"greater_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student \\'set runoff to rainfall minus absorption limit (or rainfall minus absorption)\\' inside the greater than condition. The rubric states that the student should be awarded \\'1 point if the student correctly sets runoff equal to either rainfall - absorption limit or rainfall - absorption in the \\'greater than\\' condition.\\' Based on the rubric, the student earned a score of 1.\",\\n\\t\\t\"score\": 1\\n\\t}\\n}\\n!@#@!\\nuser!~*~!idk\\nidk\\nidk\\n!@#@!\\nassistant!~*~!{\\n  \"less_than_condition\" :\\n\\t{\\n\\t\\t\"explanation\": \"The student did not mention the less than condition. The rubric states that the student should be awarded \\'0 points if the student does not mention the \\'less than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"less_than_set_absorption\" :\\n\\t{\\n\\t\\t\"explanation\": \"The student did not set absorption correctly in the less than condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set absorption in the \\'less than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"less_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not set runoff correctly in the less than condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set runoff in the \\'less than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"equal_to_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not mention the equal to condition. The rubric states that the student should be awarded \\'0 points if the student does not mention the \\'equal to\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"equal_to_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not set absorption correctly in the equal to condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set absorption in the \\'equal to\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"equal_to_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not set runoff correctly in the equal to condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set runoff in the \\'equal to\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"greater_than_condition\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not mention the greater than condition. The rubric states that the student should be awarded \\'0 points if the student does not mention the \\'greater than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"greater_than_set_absorption\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not set absorption correctly in the greater than condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set absorption in the \\'greater than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t},\\n  \"greater_than_set_runoff\" :  \\n\\t{\\n\\t\\t\"explanation\": \"The student did not set runoff correctly in the greater than condition. The rubric states that the student should be awarded \\'0 points if the student does not correctly set runoff in the \\'greater than\\' condition.\\' Based on the rubric, the student earned a score of 0.\",\\n\\t\\t\"score\": 0\\n\\t}\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROMPT_PATH, 'r', encoding='utf-8') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_response(messages):\n",
    "  start_time = time.time()\n",
    "  response = client.chat.completions.create(\n",
    "      model=MODEL,\n",
    "      messages=messages,\n",
    "      temperature=0,\n",
    "      response_format={\"type\": \"json_object\"},\n",
    "      seed=SEED)\n",
    "  total_time = time.time()-start_time\n",
    "  total_tokens = response.usage.total_tokens\n",
    "  generation = response.choices[0].message.content.strip()\n",
    "\n",
    "  return generation, total_time, total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n    \"working\": true,\\n    \"explanation\": \"The API is functioning correctly as there are no reported issues or errors in the system. All endpoints are responding as expected.\"\\n}', 0.893195390701294, 70)\n"
     ]
    }
   ],
   "source": [
    "response = get_openai_response([{\"role\":\"system\",\"content\":\"Confirm that the api is working. Respond using the following JSON schema: {'working':bool, 'explanation':str}\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED FA2 STUDENT 0.\n",
      "FINISHED FA2 STUDENT 1.\n",
      "FINISHED FA2 STUDENT 2.\n",
      "FINISHED FA2 STUDENT 3.\n",
      "FINISHED FA2 STUDENT 4.\n",
      "FINISHED FA2 STUDENT 5.\n",
      "FINISHED FA2 STUDENT 6.\n",
      "FINISHED FA2 STUDENT 7.\n",
      "FINISHED FA2 STUDENT 8.\n",
      "FINISHED FA2 STUDENT 9.\n",
      "FINISHED FA2 STUDENT 10.\n",
      "FINISHED FA2 STUDENT 11.\n",
      "FINISHED FA2 STUDENT 12.\n",
      "FINISHED FA2 STUDENT 13.\n",
      "FINISHED FA2 STUDENT 14.\n",
      "FINISHED FA2 STUDENT 15.\n",
      "FINISHED FA2 STUDENT 16.\n",
      "FINISHED FA2 STUDENT 17.\n",
      "FINISHED FA2 STUDENT 18.\n",
      "FINISHED FA2 STUDENT 19.\n",
      "FINISHED FA2 STUDENT 20.\n",
      "FINISHED FA2 STUDENT 21.\n",
      "FINISHED FA2 STUDENT 22.\n",
      "FINISHED FA2 STUDENT 23.\n",
      "FINISHED FA2 STUDENT 24.\n",
      "FINISHED FA2 STUDENT 25.\n",
      "FINISHED FA2 STUDENT 26.\n",
      "FINISHED FA2 STUDENT 27.\n",
      "FINISHED FA2 STUDENT 28.\n",
      "FINISHED FA2 STUDENT 29.\n",
      "FINISHED FA2 STUDENT 30.\n",
      "FINISHED FA2 STUDENT 31.\n",
      "FINISHED FA2 STUDENT 32.\n",
      "FINISHED FA2 STUDENT 33.\n",
      "FINISHED FA2 STUDENT 34.\n",
      "FINISHED FA2 STUDENT 35.\n",
      "FINISHED FA2 STUDENT 36.\n",
      "FINISHED FA2 STUDENT 37.\n",
      "FINISHED FA2 STUDENT 38.\n",
      "FINISHED FA2 STUDENT 39.\n",
      "FINISHED FA2 STUDENT 40.\n",
      "FINISHED FA2 STUDENT 41.\n",
      "FINISHED FA2 STUDENT 42.\n",
      "FINISHED FA2 STUDENT 43.\n",
      "FINISHED FA2 STUDENT 44.\n",
      "FINISHED FA2 STUDENT 45.\n",
      "FINISHED FA2 STUDENT 46.\n",
      "FINISHED FA2 STUDENT 47.\n",
      "FINISHED FA2 STUDENT 48.\n",
      "FINISHED FA2 STUDENT 49.\n"
     ]
    }
   ],
   "source": [
    "DOUBLED_COLS = []\n",
    "for col in FA_COLS:\n",
    "  DOUBLED_COLS.append(col+\"_explanation\")\n",
    "  DOUBLED_COLS.append(col+\"_score\")\n",
    "\n",
    "results = [DOUBLED_COLS+[\"total_score\",\"total_time_s\",\"total_tokens\"]]\n",
    "\n",
    "prompt_messages = prompt.split(LINE_DELIM)\n",
    "assert len(prompt_messages) == N_PROMPT_MESSAGES\n",
    "\n",
    "system_role, system_content = prompt_messages[0].split(ROLE_CONTENT_DELIM)\n",
    "user_role1, user_content1 = prompt_messages[1].split(ROLE_CONTENT_DELIM)\n",
    "assistant_role1, assistant_content1 = prompt_messages[2].split(ROLE_CONTENT_DELIM)\n",
    "user_role2, user_content2 = prompt_messages[3].split(ROLE_CONTENT_DELIM)\n",
    "assistant_role2, assistant_content2 = prompt_messages[4].split(ROLE_CONTENT_DELIM)\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "  messages = [\n",
    "      {\"role\":system_role,\"content\":system_content},\n",
    "      {\"role\":user_role1,\"content\":user_content1},\n",
    "      {\"role\":assistant_role1,\"content\":assistant_content1},\n",
    "      {\"role\":user_role2,\"content\":user_content2},\n",
    "      {\"role\":assistant_role2,\"content\":assistant_content2},\n",
    "      {\"role\":\"user\",\"content\":row['response']}\n",
    "  ]\n",
    "\n",
    "  generation, total_time, total_tokens = get_openai_response(messages)\n",
    "  generation_data = json.loads(generation)\n",
    "\n",
    "  for k in FA_COLS:\n",
    "    FA_COLS_DICT[k] = {\"explanation\":generation_data[k][\"explanation\"], \"score\":int(generation_data[k][\"score\"])}\n",
    "\n",
    "  total_score = sum([FA_COLS_DICT[k][\"score\"] for k in FA_COLS_DICT.keys()])\n",
    "\n",
    "  new_result = []\n",
    "  for k in FA_COLS:\n",
    "    new_result.append(FA_COLS_DICT[k][\"explanation\"])\n",
    "    new_result.append(FA_COLS_DICT[k][\"score\"])\n",
    "  new_result.extend([total_score, total_time, total_tokens])\n",
    "\n",
    "  results.append(new_result)\n",
    "\n",
    "  print(f\"FINISHED FA{FA} STUDENT {idx}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results[1:],columns=results[0])\n",
    "df = pd.concat([df,df_results],axis=1)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf=RESULTS_PATH,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro‑F1: 0.7200\n",
      "QWK:      0.9603\n"
     ]
    }
   ],
   "source": [
    "y_true = df[\"score\"].astype(int)\n",
    "y_pred = df[\"total_score\"].astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "print(f\"Micro‑F1: {f1:.4f}\")\n",
    "print(f\"QWK:      {qwk:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro‑F1: 72.00 ± 12.00\n",
      "QWK:      96.03 ± 3.04\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "f1_samples   = []\n",
    "kappa_samples = []\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "for _ in range(N_BOOTSTRAP):\n",
    "    idx = rng.integers(0, n, n)\n",
    "    y_t = y_true.iloc[idx].values\n",
    "    y_p = y_pred.iloc[idx].values\n",
    "\n",
    "    f1_samples.append(\n",
    "        f1_score(y_t, y_p, average=\"micro\")\n",
    "    )\n",
    "    kappa_samples.append(\n",
    "        cohen_kappa_score(y_t, y_p, weights=\"quadratic\")\n",
    "    )\n",
    "\n",
    "ci_f1   = np.percentile(f1_samples, [2.5, 97.5])\n",
    "ci_kappa = np.percentile(kappa_samples, [2.5, 97.5])\n",
    "\n",
    "moe_f1   = (ci_f1[1]   - ci_f1[0])   / 2\n",
    "moe_kappa = (ci_kappa[1] - ci_kappa[0]) / 2\n",
    "\n",
    "print(f\"Micro‑F1: {f1*100:.2f} ± {moe_f1*100:.2f}\")\n",
    "print(f\"QWK:      {qwk*100:.2f} ± {moe_kappa*100:.2f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
